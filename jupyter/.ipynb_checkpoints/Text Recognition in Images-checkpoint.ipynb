{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognizing single characters\n",
    "\n",
    "In this brief analysis we focus on the problem of reading some text from an image. To be more precise, in this first stage we will concentrate on recognizing single handwritten characters.\n",
    "\n",
    "## The dataset\n",
    "\n",
    "The dataset we used in this preliminary stage is a quite commmon one. It is the eMNIST training and test set, which is based on the MNIST set but extended with letters. All the data is presented in the same format as the MNIST dataset, which means that each image is 28x28 pixels big, in grayscale and containst one single handwritten character. We attach below some examples of the images included in this set.\n",
    "\n",
    "![](imgs/B1.png)\n",
    "\n",
    "![](imgs/B2.png)\n",
    "\n",
    "![](imgs/B3.png)\n",
    "\n",
    "![](imgs/B4.png)\n",
    "\n",
    "## Feed-forward neural network\n",
    "\n",
    "The most simple approach to this problem is by building a linear, feed-forward neural network. Being a first try, we didn't expect much from this experiment, but the network turned out to perform quite good. We managed to reach 80.1% accuracy on the eMNIST test set with a 6-layers feed-forward neural network. The code follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Function that returns the value of the sigmoid function for a certain input value\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "# Function that returns the value of the derivative of the sigmoid function for a certain input value\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "# Mnist class\n",
    "\n",
    "class Mnist(object):\n",
    "\n",
    "    # Function that loads the mnist training and test data from csv files and prepares two arrays to be pickled\n",
    "    @staticmethod\n",
    "    def _load_(source_tr, source_te, destination):\n",
    "        # Array of couples (image, result) where 'image' is an array of 784 floats between 0 and 1, and 'result' is an array of 36 bits (either 0 or 1) representing the neural netork output\n",
    "        mnist_training_data = []\n",
    "        # Array of couples (image, result) where 'image' is the same as above, and 'result' is an integer between 0 and 35 representing the neural network output\n",
    "        mnist_test_data = []\n",
    "        # Training set array\n",
    "        with open(source_tr, \"r\") as f_tr:\n",
    "            lines_tr = f_tr.readlines()\n",
    "        for line_tr in lines_tr:\n",
    "            line_tr = line_tr.replace(\"\\n\", \"\")\n",
    "            bits_tr = line_tr.split(\",\")\n",
    "            result_tr = np.array([[float(0 if i != int(bits_tr[0]) else 1)] for i in range(36)])\n",
    "            mnist_training_data.append((np.array([[float(bit_tr) / 255] for bit_tr in bits_tr[1:]], dtype = \"float32\"), result_tr))\n",
    "        # Test set array\n",
    "        with open(source_te, \"r\") as f_te:\n",
    "            lines_te = f_te.readlines()\n",
    "        for line_te in lines_te:\n",
    "            line_te = line_te.replace(\"\\n\", \"\")\n",
    "            bits_te = line_te.split(\",\")\n",
    "            mnist_test_data.append((np.array([[float(bit_te) / 255] for bit_te in bits_te[1:]], dtype = \"float32\"), int(bits_te[0])))\n",
    "        return (mnist_training_data, mnist_test_data)\n",
    "\n",
    "    # Function that pickles the arrays into a binary file\n",
    "    @staticmethod\n",
    "    def pickle(source_tr, source_te, destination):\n",
    "        mnist_training_data, mnist_test_data = Mnist._load_(source_tr, source_te, destination)\n",
    "        with open(destination, \"wb\") as f:\n",
    "            pickle.dump((mnist_training_data, mnist_test_data), f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    # Function that, given a binary file, unpickles the content, returning the arrays\n",
    "    @staticmethod\n",
    "    def unpickle(source):\n",
    "        with open(source, \"rb\") as f:\n",
    "            mnist_training_data, mnist_test_data = pickle.load(f)\n",
    "        return (mnist_training_data, mnist_test_data)\n",
    "\n",
    "# Ann class\n",
    "\n",
    "class Ann(object):\n",
    "\n",
    "    # Function that pickles a neural network class instance into a binary file\n",
    "    @staticmethod\n",
    "    def pickle(ann, destination):\n",
    "        with open(destination, \"wb\") as f:\n",
    "            pickle.dump(ann, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    # Function that unpickles the given ANN pickled file\n",
    "    @staticmethod\n",
    "    def unpickle(source):\n",
    "        with open(source, \"rb\") as f:\n",
    "            ann = pickle.load(f)\n",
    "        return ann\n",
    "\n",
    "# NeuralNetwork class\n",
    "\n",
    "class NeuralNetwork(object):\n",
    "\n",
    "    # Constructor - initializes a network with the given dimensions (dimens must be a list of the neurons contained in each layer)\n",
    "\n",
    "    def __init__(self, dimens):\n",
    "        self.num_layers = len(dimens)\n",
    "        self.dimens = dimens\n",
    "        self.weights = [np.random.randn(y, x) for x, y in zip(self.dimens[:-1], self.dimens[1:])]\n",
    "        self.biases = [np.random.randn(y, 1) for y in self.dimens[1:]]\n",
    "\n",
    "    # Function that, given an input \"a\" for the network, returns the corresponding output\n",
    "\n",
    "    def feedforward(self, a):\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            a = sigmoid(np.dot(w, a) + b)\n",
    "        return a\n",
    "\n",
    "    # Function that, for every epoch, shuffles the training data and creates mini batches (according to the stochastic gradient descent algoritm) with the given size, then it calls the \"update_mini_batch\" function. If \"test_data\" is given, a test against it is done at the end of each epoch of training\n",
    "\n",
    "    def sgd(self, training_data, epochs, mini_batch_size, eta, test_data = None):\n",
    "        if test_data: n_test = len(test_data)\n",
    "        n = len(training_data)\n",
    "        for e in range(epochs):\n",
    "            np.random.shuffle(training_data)\n",
    "            mini_batches = [training_data[k:k+mini_batch_size] for k in range(0, n, mini_batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch, eta)\n",
    "            if test_data:\n",
    "                print(\"Epoch %s: %s / %s\" % (e, self.evaluate(test_data), n_test))\n",
    "            else:\n",
    "                print(\"Epoch %s complete\" % (e))\n",
    "            eta *= 0.95\n",
    "\n",
    "    # Function that updates weights and biases basing on the nabla_w and nabla_b vertors, which are computed by the \"backprop\" function\n",
    "\n",
    "    def update_mini_batch(self, mini_batch, eta):\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        for x, y in mini_batch:\n",
    "            delta_nabla_w, delta_nabla_b = self.backprop(x, y)\n",
    "            nabla_w = [nw + dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "            nabla_b = [nb + dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "        self.weights = [w - (eta / len(mini_batch)) * nw for w, nw in zip(self.weights, nabla_w)]\n",
    "        self.biases = [b - (eta / len(mini_batch)) * nb for b, nb in zip(self.biases, nabla_b)]\n",
    "\n",
    "    # Function that calculates the gradient of the cost function (with respect to weights and biases) by using the backpropagation algorithm\n",
    "\n",
    "    def backprop(self, x, y):\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        # Feedforward\n",
    "        activation = x\n",
    "        activations = [x]\n",
    "        zs = []\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            z = np.dot(w, activation) + b\n",
    "            zs.append(z)\n",
    "            activation = sigmoid(z)\n",
    "            activations.append(activation)\n",
    "        # Backward pass\n",
    "        delta = self.cost_derivative(activations[-1], y) * sigmoid_prime(zs[-1])\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "        nabla_b[-1] = delta\n",
    "        for l in range(2, self.num_layers):\n",
    "            z = zs[-l]\n",
    "            sp = sigmoid_prime(z)\n",
    "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "            nabla_b = delta\n",
    "        return (nabla_w, nabla_b)\n",
    "\n",
    "    # Function that returns the derivative of the cost function, given the output of the net and the expected result\n",
    "\n",
    "    def cost_derivative(self, output_activations, y):\n",
    "        return (output_activations - y)\n",
    "\n",
    "    # Function that evaluates the neural network precision against a test dataset\n",
    "\n",
    "    def evaluate(self, test_data):\n",
    "        test_results = [(np.argmax(self.feedforward(x)), y) for (x, y) in test_data]\n",
    "        return sum(int(x == y) for (x, y) in test_results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    training_set, test_set = Mnist.unpickle(\"res/mnist/emnist-balanced.pkl\")\n",
    "    network = NeuralNetwork([784, 100, 80, 60, 40, 36])\n",
    "    network.sgd(training_set, 50, 10, 1.0, test_set)\n",
    "    Ann.pickle(network, \"res/network/ann_4h100806040_%s.pkl\" % (network.evaluate(test_set)*100/14400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional neural network\n",
    "\n",
    "We also tried using a CNN to try getting better results, but actually there was quite little improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.preprocessing.image import *\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.utils import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.io import imread\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import gc; gc.enable()\n",
    "from cv2 import *\n",
    "\n",
    "# Test values\n",
    "showImages = False\n",
    "baseDir = \"\"\n",
    "mnistDir = os.path.join(baseDir, \"mnist\")\n",
    "\n",
    "toId = {}\n",
    "toChar = {}\n",
    "\n",
    "with open(os.path.join(mnistDir, \"emnist-balanced-mapping-to-char.txt\")) as f:\n",
    "    for line in f.read().split(\"\\n\"):\n",
    "        a,b = line.split(\" \")\n",
    "        toChar[int(a)] = b\n",
    "        toId[b] = a\n",
    "\n",
    "numClasses = len(toChar)\n",
    "\n",
    "# print(numClasses, \"classes\")\n",
    "# print(\"toChar =\", toChar)\n",
    "# print(\"toId =\", toId)\n",
    "\n",
    "train = pd.read_csv(os.path.join(mnistDir, \"emnist-balanced-train-uppercase.csv\"), header=None).to_numpy()\n",
    "\n",
    "x = np.transpose(train[:, 1:].reshape((-1, 28, 28, 1)), (0, 2, 1, 3))\n",
    "y = to_categorical(train[:, 0], num_classes=numClasses)\n",
    "\n",
    "x = (x - x.mean()) / x.std()\n",
    "\n",
    "# print(x.shape)\n",
    "# print(y.shape)\n",
    "\n",
    "generator = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False\n",
    ")\n",
    "\n",
    "generator.fit(x)\n",
    "\n",
    "if showImages:\n",
    "    for i in range(100):\n",
    "        d, l = x[i], y[i]\n",
    "        #d = d.reshape((28, 28))\n",
    "        # print(toChar[np.argmax(l)])\n",
    "        #print(d)\n",
    "        plt.title(\"\" + str(toChar[np.argmax(l)]) + \" - \" + str(l))\n",
    "        plt.imshow(d[:, :, 0], cmap=\"Greys\")\n",
    "        plt.show()\n",
    "\n",
    "lrDecay = LearningRateScheduler(lambda epoch: 0.001 * np.power(0.95, epoch))\n",
    "saver = ModelCheckpoint(\"model1.model\")\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(InputLayer(input_shape=(28, 28, 1)))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size = 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, kernel_size = 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size = 4, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(numClasses, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=Adam(0.001), loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "stepsPerEpoch = 128\n",
    "model.fit_generator(generator.flow(x, y, batch_size=stepsPerEpoch),\n",
    "                    steps_per_epoch=len(x) // stepsPerEpoch,\n",
    "                    epochs=50, callbacks=[lrDecay, saver])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognizing strings\n",
    "\n",
    "In this second part we concentrate on the task of reading some text (which is composed by more that one single character) from an image. We will assume that all the images contain texts written in standard fonts (there are no handwritten characters).\n",
    "\n",
    "In order to achieve this result, we divided this complex problem into three subtasks:\n",
    "- try to cut the entire image into the single letters and characters;\n",
    "- run a neural network on the single characters and recognize them;\n",
    "- merge the two results and return the complete text contained in the original image.\n",
    "\n",
    "## The dataset\n",
    "\n",
    "As already said, the dataset is composed of images of texts written in standar fonts. They include dates, words from a dictionary, and even names or IBANs. Below there are some examples.\n",
    "\n",
    "![](imgs/A1.png)\n",
    "\n",
    "![](imgs/A2.png)\n",
    "\n",
    "![](imgs/A2.png)\n",
    "\n",
    "![](imgs/A4.png)\n",
    "\n",
    "We can note that many of the images may contain random lines and even some noise.\n",
    "\n",
    "## Splitting the image into the single characters\n",
    "\n",
    "This is actually the hardest part of the problem, as there is no algorithm that is guaranteed to work in all the situations that may occur. So, we had to formulate different euristics and try to do the best to separate the single characters.\n",
    "\n",
    "First of all, we focused on the idea that, when a text is clearly written, a single character is made of single pixels which are all contiguous (apart from the lowercase 'i', that can be recognised even if considered without the little dot on the top). We developed this idea and made slight adjustments looking at the pixels next to each border of the recognised characters, merging contiguous boxes which looked like one single character, and discarding boxes which have incompatible dimensions (in order to ignore dots and random lines).\n",
    "\n",
    "Follows a snippet of the code we used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os.path\n",
    "import queue\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "# Test values (the first of the images above)\n",
    "DIR = \"imgs\"\n",
    "IMAGE = \"ACJOWW40Z13U616M.jpg\"\n",
    "\n",
    "# Function that checks if a given pixel is black or not\n",
    "def isBlack(x):\n",
    "    return x < 100\n",
    "\n",
    "# Function that processes an image, splitting it in the single characters\n",
    "def process(dir=\"\", name=\"img.jpg\"):\n",
    "    img = Image.open(os.path.join(dir, name))\n",
    "    name = name.split(\".\")[0]\n",
    "    img = img.convert(\"L\")\n",
    "    img = np.array(img)\n",
    "    img = img * 255. / img.max()\n",
    "    img[img > 220] = 255\n",
    "    img[img < 255] = 0\n",
    "    img = PIL.Image.fromarray(np.uint8(img))\n",
    "    w, h = img.size\n",
    "    img = np.array(img)\n",
    "    mask = np.zeros(img.shape)\n",
    "    boxes = []\n",
    "\n",
    "    for j in range(1, w-1):\n",
    "        for i in range(1, h-1):\n",
    "            s = True\n",
    "            for a in range(-1, 2):\n",
    "                for b in range(-1, 2):\n",
    "                    if (a != 0 or b != 0) and img[i+a][j+b] == 0:\n",
    "                        s = False\n",
    "            if s:\n",
    "                mask[i][j] = 1\n",
    "                img[i][j] = 255\n",
    "\n",
    "    for j in range(w):\n",
    "        for i in range(h):\n",
    "            if isBlack(img[i][j]) and mask[i][j] == 0:\n",
    "                q = queue.Queue(maxsize=w*h)\n",
    "                q.put((i, j))\n",
    "                xmin, xmax, ymin, ymax = i, i, j, j\n",
    "                while not q.empty():\n",
    "                    x, y = q.get()\n",
    "                    for a in range(-2, 2+1):\n",
    "                        for b in range(-1, 1+1):\n",
    "                            if x+a >= 0 and x+a < h and y+b >= 0 and y+b < w and mask[x+a][y+b] == 0 and isBlack(img[x+a][y+b]):\n",
    "                                mask[x+a][y+b] = 1\n",
    "                                q.put((x+a, y+b))\n",
    "                                xmin = min(xmin, x+a)\n",
    "                                xmax = max(xmax, x+a)\n",
    "                                ymin = min(ymin, y+b)\n",
    "                                ymax = max(ymax, y+b)\n",
    "                dex = xmax - xmin\n",
    "                dey = ymax - ymin\n",
    "                if dex > 5 and dey > 5 and 1.3 * dex > dey:\n",
    "                    boxes.append((xmin, xmax, ymin, ymax))\n",
    "\n",
    "    n = len(boxes)\n",
    "    imgBoxes = np.copy(img)\n",
    "    # print(n)\n",
    "    for box in boxes:\n",
    "        xmin, xmax, ymin, ymax = box\n",
    "        for k in range(xmin, xmax+1):\n",
    "            imgBoxes[k][ymin] = 192\n",
    "            imgBoxes[k][ymax] = 192\n",
    "        for k in range(ymin, ymax+1):\n",
    "            imgBoxes[xmin][k] = 192\n",
    "            imgBoxes[xmax][k] = 192\n",
    "    # PIL.Image.fromarray(np.uint8(imgBoxes)).show()\n",
    "    img = PIL.Image.fromarray(np.uint8(img))\n",
    "\n",
    "    if len(boxes) == len(name):\n",
    "        i = 0\n",
    "        for box in boxes:\n",
    "            xmin, xmax, ymin, ymax = box\n",
    "            s = img.crop((ymin-2, xmin-2, ymax+2, xmax+2))\n",
    "            s.save(\"out/%s_%s.jpg\" % (name, i))\n",
    "            i += 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process(DIR, IMAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This piece of code processes an image and draws grey boxes around each character it recognizes, then saves a new image for each of them. We run this small script over all the dataset we were given in order to generate a suitable training dataset for a neural network which is able to recognize the single characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recognizing the single characters\n",
    "\n",
    "After having a set of single characters, we were able to train a neural network to recognize them. Actually, we used a network which is pretty similar to the CNN we used to recognize the eMNIST set of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import keras\n",
    "from keras.preprocessing.image import *\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.utils import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.io import imread\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import gc; gc.enable()\n",
    "from cv2 import *\n",
    "\n",
    "# Test data\n",
    "showImages = False\n",
    "baseDir = \"\"\n",
    "wordsDir = os.path.join(baseDir, \"words\")\n",
    "\n",
    "#mappings\n",
    "toId = {'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25, 'A': 26, 'B': 27, 'C': 28, 'D': 29, 'E': 30, 'F': 31, 'G': 32, 'H': 33, 'I': 34, 'J': 35, 'K': 36, 'L': 37, 'M': 38, 'N': 39, 'O': 40, 'P': 41, 'Q': 42, 'R': 43, 'S': 44, 'T': 45, 'U': 46, 'V': 47, 'W': 48, 'X': 49, 'Y': 50, 'Z': 51, '0': 52, '1': 53, '2': 54, '3': 55, '4': 56, '5': 57, '6': 58, '7': 59, '8': 60, '9': 61, '_': 62}\n",
    "toChar = {0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g', 7: 'h', 8: 'i', 9: 'j', 10: 'k', 11: 'l', 12: 'm', 13: 'n', 14: 'o', 15: 'p', 16: 'q', 17: 'r', 18: 's', 19: 't', 20: 'u', 21: 'v', 22: 'w', 23: 'x', 24: 'y', 25: 'z', 26: 'A', 27: 'B', 28: 'C', 29: 'D', 30: 'E', 31: 'F', 32: 'G', 33: 'H', 34: 'I', 35: 'J', 36: 'K', 37: 'L', 38: 'M', 39: 'N', 40: 'O', 41: 'P', 42: 'Q', 43: 'R', 44: 'S', 45: 'T', 46: 'U', 47: 'V', 48: 'W', 49: 'X', 50: 'Y', 51: 'Z', 52: '0', 53: '1', 54: '2', 55: '3', 56: '4', 57: '5', 58: '6', 59: '7', 60: '8', 61: '9', 62: '_'}\n",
    "\n",
    "numClasses = len(toChar)\n",
    "\n",
    "# print(numClasses, \"classes\")\n",
    "# print(\"toChar =\", toChar)\n",
    "# print(\"toId =\", toId)\n",
    "\n",
    "#read dataset\n",
    "trainData = pd.read_csv(\"dataset.csv\", header=None)\n",
    "\n",
    "#code provided by Corrado Alessio (HumanProtein challlenge)\n",
    "# https://www.dropbox.com/sh/hsgzowq3elk7n68/AABM_cJ_r3zxkljYNRv8YPRra?dl=0)\n",
    "#wraps input in a keras sequence\n",
    "class MyDataGenerator(keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, paths, labels, batch_size, shape, shuffle=False, use_cache=False, augment=None, directory=\"all\"):\n",
    "        self.augment = augment\n",
    "        self.directory = directory\n",
    "        self.paths, self.label = paths, to_categorical(labels)\n",
    "        self.batch_size = batch_size\n",
    "        self.shape = shape\n",
    "        self.shuffle = shuffle\n",
    "        self.use_cache = use_cache\n",
    "        if use_cache == True:\n",
    "            self.cache = np.zeros((paths.shape[0], shape[0], shape[1], shape[2]))\n",
    "            self.is_cached = np.zeros((paths.shape[0]))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.paths) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        indexes = self.indexes[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "\n",
    "        paths = self.paths[indexes]\n",
    "        X = np.zeros((paths.shape[0], self.shape[0], self.shape[1], self.shape[2]))\n",
    "        # Generate data\n",
    "        if self.use_cache == True:\n",
    "            X = self.cache[indexes]\n",
    "            for i, path in enumerate(paths[np.where(self.is_cached[indexes] == 0)]):\n",
    "                image = self.__load_image(path)\n",
    "                self.is_cached[indexes[i]] = 1\n",
    "                self.cache[indexes[i]] = image\n",
    "                X[i] = image\n",
    "        else:\n",
    "            for i, path in enumerate(paths):\n",
    "                X[i] = self.__load_image(path)\n",
    "\n",
    "        y = np.stack(self.labels[indexes])\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "\n",
    "        # Updates indexes after each epoch\n",
    "        self.indexes = np.arange(len(self.paths))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Create a generator that iterate over the Sequence.\"\"\"\n",
    "        for item in (self[i] for i in range(len(self))):\n",
    "            yield item\n",
    "\n",
    "    def __load_image(self, path):\n",
    "        return augment.random_transform(np.array(Image.open(path).convert(\"L\").resize((self.shape[0], self.shape[1]), PIL.Image.ANTIALIAS))\\\n",
    "            .reshape(self.shape))\n",
    "\n",
    "augment = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False\n",
    ")\n",
    "\n",
    "gen = MyDataGenerator(trainData[0], trainData[1], 32, (28, 28, 1), augment=augment)\n",
    "\n",
    "#annealing and model saving\n",
    "lrDecay = LearningRateScheduler(lambda epoch: 0.001 * np.power(0.95, epoch))\n",
    "saver = ModelCheckpoint(\"train_2.model\")\n",
    "\n",
    "model = Sequential()\n",
    "#automatic input normalization\n",
    "model.add(BatchNormalization(input_shape=(28, 28, 1)))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size = 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, kernel_size = 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu')) #differentiable pooling\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size = 4, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(numClasses, activation='softmax'))  #one hot result\n",
    "\n",
    "model.compile(optimizer=Adam(0.001), loss=\"categorical_crossentropy\", metrics=[\"acc\"])  #standard optimizer with annealing\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit_generator(gen, epochs=50, callbacks=[lrDecay, saver])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network trained with this data was able to reach 91.0% accuracy in our tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String recognition\n",
    "\n",
    "Given an image containing some text, the program executes three main steps:\n",
    "- tries to split it in images containing single characters;\n",
    "- processes all these images with the trained neural network, recognizing the characters;\n",
    "- combines all the characters in a string, which is then returned.\n",
    "\n",
    "The software, actually, is just a combination of the two parts already described in sections 2.2 and 2.3. We attach here the complete code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import queue\n",
    "import os.path\n",
    "import keras\n",
    "from keras.preprocessing.image import *\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.utils import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "toId = {'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25, 'A': 26, 'B': 27, 'C': 28, 'D': 29, 'E': 30, 'F': 31, 'G': 32, 'H': 33, 'I': 34, 'J': 35, 'K': 36, 'L': 37, 'M': 38, 'N': 39, 'O': 40, 'P': 41, 'Q': 42, 'R': 43, 'S': 44, 'T': 45, 'U': 46, 'V': 47, 'W': 48, 'X': 49, 'Y': 50, 'Z': 51, '0': 52, '1': 53, '2': 54, '3': 55, '4': 56, '5': 57, '6': 58, '7': 59, '8': 60, '9': 61, '_': 62}\n",
    "toChar = {0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g', 7: 'h', 8: 'i', 9: 'j', 10: 'k', 11: 'l', 12: 'm', 13: 'n', 14: 'o', 15: 'p', 16: 'q', 17: 'r', 18: 's', 19: 't', 20: 'u', 21: 'v', 22: 'w', 23: 'x', 24: 'y', 25: 'z', 26: 'A', 27: 'B', 28: 'C', 29: 'D', 30: 'E', 31: 'F', 32: 'G', 33: 'H', 34: 'I', 35: 'J', 36: 'K', 37: 'L', 38: 'M', 39: 'N', 40: 'O', 41: 'P', 42: 'Q', 43: 'R', 44: 'S', 45: 'T', 46: 'U', 47: 'V', 48: 'W', 49: 'X', 50: 'Y', 51: 'Z', 52: '0', 53: '1', 54: '2', 55: '3', 56: '4', 57: '5', 58: '6', 59: '7', 60: '8', 61: '9', 62: '_'}\n",
    "\n",
    "def isBlack(x):\n",
    "    return x < 100\n",
    "\n",
    "def process(dir=\"\", name=\"img.jpg\"):\n",
    "    img = Image.open(os.path.join(dir, name))\n",
    "    name = name.split(\".\")[0]\n",
    "    img = img.convert(\"L\")\n",
    "    img = np.array(img)\n",
    "    img = img * 255. / img.max()\n",
    "    img[img > 220] = 255\n",
    "    img[img < 255] = 0\n",
    "    #img = np.array([list(map(lambda x: 0 if x < 220 else 255, img_row)) for img_row in img])\n",
    "    img = PIL.Image.fromarray(np.uint8(img))\n",
    "    w, h = img.size\n",
    "    img = np.array(img)\n",
    "    mask = np.zeros(img.shape)\n",
    "    boxes = []\n",
    "\n",
    "    for j in range(1, w-1):\n",
    "        for i in range(1, h-1):\n",
    "            s = True\n",
    "            for a in range(-1, 2):\n",
    "                for b in range(-1, 2):\n",
    "                    if (a != 0 or b != 0) and img[i+a][j+b] == 0:\n",
    "                        s = False\n",
    "            if s:\n",
    "                mask[i][j] = 1\n",
    "                img[i][j] = 255\n",
    "\n",
    "    for j in range(w):\n",
    "        for i in range(h):\n",
    "            if isBlack(img[i][j]) and mask[i][j] == 0:\n",
    "                q = queue.Queue(maxsize=w*h)\n",
    "                q.put((i, j))\n",
    "                xmin, xmax, ymin, ymax = i, i, j, j\n",
    "                while not q.empty():\n",
    "                    x, y = q.get()\n",
    "                    for a in range(-2, 2+1):\n",
    "                        for b in range(-1, 1+1):\n",
    "                            if x+a >= 0 and x+a < h and y+b >= 0 and y+b < w and mask[x+a][y+b] == 0 and isBlack(img[x+a][y+b]):\n",
    "                                mask[x+a][y+b] = 1\n",
    "                                q.put((x+a, y+b))\n",
    "                                xmin = min(xmin, x+a)\n",
    "                                xmax = max(xmax, x+a)\n",
    "                                ymin = min(ymin, y+b)\n",
    "                                ymax = max(ymax, y+b)\n",
    "                dex = xmax - xmin\n",
    "                dey = ymax - ymin\n",
    "                if dex > 5 and dey > 5 and 1.3 * dex > dey:\n",
    "                    boxes.append((xmin, xmax, ymin, ymax))\n",
    "\n",
    "    n = len(boxes)\n",
    "    \"\"\"l = 0\n",
    "    for box in boxes:\n",
    "        xmin, xmax, ymin, ymax = box\n",
    "        l += xmax\n",
    "    l /= n\"\"\"\n",
    "\n",
    "    imgBoxes = np.copy(img)\n",
    "\n",
    "    # print(n)\n",
    "    for box in boxes:\n",
    "        xmin, xmax, ymin, ymax = box\n",
    "        for k in range(xmin, xmax+1):\n",
    "            imgBoxes[k][ymin] = 192\n",
    "            imgBoxes[k][ymax] = 192\n",
    "        for k in range(ymin, ymax+1):\n",
    "            imgBoxes[xmin][k] = 192\n",
    "            imgBoxes[xmax][k] = 192\n",
    "\n",
    "    #PIL.Image.fromarray(np.uint8(imgBoxes)).show()\n",
    "    img = PIL.Image.fromarray(np.uint8(img))\n",
    "\n",
    "    res = []\n",
    "\n",
    "    for box in boxes:\n",
    "        xmin, xmax, ymin, ymax = box\n",
    "        res.append(np.array(img.crop((ymin-2, xmin-2, ymax+2, xmax+2)).resize((28,28))).reshape((28,28,1)))\n",
    "        #s.save(\"out/%s_%s.jpg\" % (name, i))\n",
    "\n",
    "    return np.array(res)\n",
    "\n",
    "'''\n",
    "for d in data:\n",
    "    plt.imshow(d)\n",
    "    plt.show()\n",
    "'''\n",
    "\n",
    "model = load_model(\"train_1_1.model\")\n",
    "model.summary()\n",
    "\n",
    "for dir in [\"words/all\"]:  #predict all images\n",
    "    for name in os.listdir(dir):\n",
    "        data = process(\"words/all\", name)\n",
    "\n",
    "        res = model.predict(data, verbose=1)\n",
    "\n",
    "        res = np.argmax(res, axis=1)\n",
    "\n",
    "        pred = \"\".join([toChar[x] for x in res])\n",
    "\n",
    "        #show results (one at a time)\n",
    "        plt.imshow(Image.open(os.path.join(\"words/all\", name)))\n",
    "        plt.title(pred)\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
